{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Forecasting using DeepAR\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Prepare Train and Test Datasets](#Prepare-Train-and-Test-Datasets)\n",
    "3. [Model Training](#Model-Training)\n",
    "   1. [Define-Hyperparameters](#Define-Hyperparameters)\n",
    "   2. [Model Fitting](#Model-Fitting)\n",
    "4. [Deploy Trained Model](#Deploy-Trained-Model)\n",
    "5. [Consume Deployed Model](#Consume-Deployed-Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The [kaggle](https://www.kaggle.com/manjeetsingh/retaildataset) dataset contains historical sales for 45 stores, with each store belonging to a specific type (location and performance) and size. The retailer runs several promotional markdowns throughout the year. These markdowns precede holidays, such as SuperBowl, Labor Day, Thanksgiving, and Christmas.\n",
    "\n",
    "We will forecast category sales for store 20. Remember that in the previous notebook where we explored sales data, we saved sales of store 20 in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sagemaker.amazon.common as smac    \n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/ec2-user/SageMaker/DeepAR\n",
      "Building wheels for collected packages: deepar\n",
      "  Running setup.py bdist_wheel for deepar ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-zkxguazr/wheels/72/24/18/bb0a1089f91d18faef4459629e814fa0a17bd873e148c04878\n",
      "Successfully built deepar\n",
      "Installing collected packages: deepar\n",
      "Successfully installed deepar-0.0.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "/home/ec2-user/SageMaker/DeepAR\n"
     ]
    }
   ],
   "source": [
    "#Navidate to deep-ar directory to install the deepar package containing commonly used functions\n",
    "path = \"..\"\n",
    "os.chdir(path)\n",
    "\n",
    "#install predefined functions\n",
    "!pip install .\n",
    "\n",
    "#Navigate to the parent directory to train the DeepAR model\n",
    "# org_path = \"..\"\n",
    "# os.chdir(org_path)\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepar as da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train and Test Datasets\n",
    "The datasets should be in JSON Lines format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_key      = 'deepar_sales_training.json'\n",
    "test_key       = 'deepar_sales_test.json'\n",
    "#Prediction and context length for training the DeepAR model\n",
    "prediction_length = 9\n",
    "salesfn = 'data/store20_sales.csv'\n",
    "\n",
    "salesdf = da.retailsales.prepareSalesData(salesfn)\n",
    "testSet = da.retailsales.getTestSales(salesdf, test_key)\n",
    "trainingSet = da.retailsales.getTrainSales(salesdf, train_key, prediction_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We have only looked at store 20 sales. However, you can train on all store sales by including store number in the category list - for each series in train and test sets, include \"cat\": [department number, store number]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Input data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket         = 'ai-in-aws'\n",
    "prefix         = 'deepar-weekly-sales'\n",
    "\n",
    "train_prefix   = '{}/{}'.format(prefix, 'train')\n",
    "test_prefix    = '{}/{}'.format(prefix, 'test')\n",
    "output_prefix  = '{}/{}'.format(prefix, 'output')\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "train_path = sagemaker_session.upload_data(train_key, bucket=bucket, key_prefix=train_prefix)\n",
    "test_path = sagemaker_session.upload_data(test_key, bucket=bucket, key_prefix=test_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "output_path = r's3://{0}/{1}'.format(bucket, output_prefix) \n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name, 'forecasting-deepar')\n",
    "\n",
    "deepAR = sagemaker.estimator.Estimator(container,\n",
    "                                   role,\n",
    "                                   train_instance_count=1,\n",
    "                                   train_instance_type='ml.c4.xlarge',\n",
    "                                   output_path=output_path,\n",
    "                                   sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"time_freq\": 'W', # weekly series\n",
    "    \"context_length\": prediction_length, # how many data points are we going to look at before predicting\n",
    "    \"prediction_length\": prediction_length, # number of data points to predict\n",
    "    \"num_cells\": \"40\", # of cells to use in each of the hidden layers\n",
    "    \"num_layers\": \"2\", # of hidden layers\n",
    "    \"likelihood\": \"gaussian\",\n",
    "    \"epochs\": \"300\", # max number of passses over the training data\n",
    "    \"mini_batch_size\": \"32\", # size of the mini batches used during training\n",
    "    \"learning_rate\": \"0.00001\",\n",
    "    \"dropout_rate\": \"0.05\", #for each iteration, a random subset of hidden neurons are not updated\n",
    "    \"early_stopping_patience\": \"10\" # stop if loss hasn't improved in 10 epochs\n",
    "}\n",
    "\n",
    "deepAR.set_hyperparameters(**hyperparameters) #** = arbitrary number of arguments to functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-07 11:52:43 Starting - Starting the training job...\n",
      "2019-09-07 11:52:45 Starting - Launching requested ML instances......\n",
      "2019-09-07 11:53:47 Starting - Preparing the instances for training......\n",
      "2019-09-07 11:54:46 Downloading - Downloading input data...\n",
      "2019-09-07 11:55:44 Training - Training image download completed. Training in progress.\n",
      "2019-09-07 11:55:44 Uploading - Uploading generated training model\n",
      "\u001b[31mArguments: train\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:30 INFO 140078896834368] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:30 INFO 140078896834368] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'dropout_rate': u'0.05', u'learning_rate': u'0.00001', u'num_cells': u'40', u'prediction_length': u'9', u'epochs': u'300', u'time_freq': u'W', u'context_length': u'9', u'num_layers': u'2', u'mini_batch_size': u'32', u'likelihood': u'gaussian', u'early_stopping_patience': u'10'}\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:30 INFO 140078896834368] Final configuration: {u'dropout_rate': u'0.05', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'0.00001', u'num_layers': u'2', u'epochs': u'300', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'32', u'likelihood': u'gaussian', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'9', u'time_freq': u'W', u'context_length': u'9', u'_kvstore': u'auto', u'early_stopping_patience': u'10'}\u001b[0m\n",
      "\u001b[31mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:30 INFO 140078896834368] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] Using early stopping with patience 10\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/deepar_sales_training.json` and will be used for training.\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/deepar_sales_training.json` and will be used for training.\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] [cardinality=auto] Inferred value of cardinality=[66] from dataset.\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=1 from dataset.\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] Training set statistics:\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] Real time series\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] number of time series: 66\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] number of observations: 8844\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] mean target length: 134\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] min/mean/max target: 223.300003052/31660.3569334/422306.25\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] mean abs(target): 31660.3569334\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] contains missing values: no\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] Small number of time series. Doing 4 number of passes over dataset per epoch.\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] Test set statistics:\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] Real time series\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] number of time series: 66\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] number of observations: 9438\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] mean target length: 143\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] min/mean/max target: 223.300003052/31667.6111166/422306.25\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] mean abs(target): 31667.6111166\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] contains missing values: no\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] nvidia-smi took: 0.0251870155334 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] Create Store: local\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 38.25211524963379, \"sum\": 38.25211524963379, \"min\": 38.25211524963379}}, \"EndTime\": 1567857331.163695, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857331.124505}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 105.64684867858887, \"sum\": 105.64684867858887, \"min\": 105.64684867858887}}, \"EndTime\": 1567857331.230332, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857331.163771}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] Epoch[0] Batch[0] avg_epoch_loss=10.386247\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=10.3862466812\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] Epoch[0] Batch[5] avg_epoch_loss=10.354410\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=10.3544095357\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] Epoch[0] Batch [5]#011Speed: 2098.42 samples/sec#011loss=10.354410\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] processed a total of 275 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 300, \"sum\": 300.0, \"min\": 300}, \"update.time\": {\"count\": 1, \"max\": 453.8118839263916, \"sum\": 453.8118839263916, \"min\": 453.8118839263916}}, \"EndTime\": 1567857331.684309, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857331.230408}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=605.813412383 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] #quality_metric: host=algo-1, epoch=0, train loss <loss>=10.2859170702\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] Saved checkpoint to \"/opt/ml/model/state_fc176d1d-1fa9-4fcc-9a25-16326f2724b5-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.057926177978516, \"sum\": 10.057926177978516, \"min\": 10.057926177978516}}, \"EndTime\": 1567857331.69499, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857331.684395}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] Epoch[1] Batch[0] avg_epoch_loss=10.352742\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=10.3527421951\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] Epoch[1] Batch[5] avg_epoch_loss=10.463127\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=10.4631269773\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] Epoch[1] Batch [5]#011Speed: 1839.84 samples/sec#011loss=10.463127\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] processed a total of 275 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 295.78495025634766, \"sum\": 295.78495025634766, \"min\": 295.78495025634766}}, \"EndTime\": 1567857331.990912, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857331.695071}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=929.453069789 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] #quality_metric: host=algo-1, epoch=1, train loss <loss>=10.5077417162\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:31 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] Epoch[2] Batch[0] avg_epoch_loss=10.509308\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=10.5093078613\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] Epoch[2] Batch[5] avg_epoch_loss=10.464574\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=10.4645737012\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] Epoch[2] Batch [5]#011Speed: 1998.67 samples/sec#011loss=10.464574\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] processed a total of 264 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 291.36109352111816, \"sum\": 291.36109352111816, \"min\": 291.36109352111816}}, \"EndTime\": 1567857332.282838, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857331.990969}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=905.756399539 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] #quality_metric: host=algo-1, epoch=2, train loss <loss>=10.5534911686\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] Epoch[3] Batch[0] avg_epoch_loss=10.172195\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=10.1721954346\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] Epoch[3] Batch[5] avg_epoch_loss=10.349593\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=10.3495928446\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] Epoch[3] Batch [5]#011Speed: 1908.29 samples/sec#011loss=10.349593\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] processed a total of 273 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 298.8882064819336, \"sum\": 298.8882064819336, \"min\": 298.8882064819336}}, \"EndTime\": 1567857332.582232, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857332.28291}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=913.01573754 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] #quality_metric: host=algo-1, epoch=3, train loss <loss>=10.4197594325\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] Epoch[4] Batch[0] avg_epoch_loss=10.478666\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=10.4786663055\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] Epoch[4] Batch[5] avg_epoch_loss=10.408140\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=10.4081397057\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] Epoch[4] Batch [5]#011Speed: 1669.49 samples/sec#011loss=10.408140\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] processed a total of 269 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 315.9358501434326, \"sum\": 315.9358501434326, \"min\": 315.9358501434326}}, \"EndTime\": 1567857332.8988, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857332.582317}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=851.141923652 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] #quality_metric: host=algo-1, epoch=4, train loss <loss>=10.3879093594\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:32 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] Epoch[5] Batch[0] avg_epoch_loss=10.582130\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=10.5821304321\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] Epoch[5] Batch[5] avg_epoch_loss=10.563750\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=10.5637499491\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] Epoch[5] Batch [5]#011Speed: 2103.46 samples/sec#011loss=10.563750\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] processed a total of 266 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 272.49693870544434, \"sum\": 272.49693870544434, \"min\": 272.49693870544434}}, \"EndTime\": 1567857333.171878, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857332.898871}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=975.764183188 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] #quality_metric: host=algo-1, epoch=5, train loss <loss>=10.4964254167\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] Epoch[6] Batch[0] avg_epoch_loss=10.303763\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=10.3037633896\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] Epoch[6] Batch[5] avg_epoch_loss=10.290083\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=10.2900829315\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] Epoch[6] Batch [5]#011Speed: 2082.38 samples/sec#011loss=10.290083\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] processed a total of 264 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 272.40490913391113, \"sum\": 272.40490913391113, \"min\": 272.40490913391113}}, \"EndTime\": 1567857333.44476, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857333.171953}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=968.807203827 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] #quality_metric: host=algo-1, epoch=6, train loss <loss>=10.579398897\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] Epoch[7] Batch[0] avg_epoch_loss=10.765924\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=10.7659235001\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] Epoch[7] Batch[5] avg_epoch_loss=10.419763\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=10.4197629293\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] Epoch[7] Batch [5]#011Speed: 1885.28 samples/sec#011loss=10.419763\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] processed a total of 266 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 290.53306579589844, \"sum\": 290.53306579589844, \"min\": 290.53306579589844}}, \"EndTime\": 1567857333.735911, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857333.444822}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=915.199443507 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] #quality_metric: host=algo-1, epoch=7, train loss <loss>=10.3462735282\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] Epoch[8] Batch[0] avg_epoch_loss=10.276547\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=10.2765474319\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] Epoch[8] Batch[5] avg_epoch_loss=10.315421\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=10.3154207865\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:33 INFO 140078896834368] Epoch[8] Batch [5]#011Speed: 2094.85 samples/sec#011loss=10.315421\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] processed a total of 261 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 301.602840423584, \"sum\": 301.602840423584, \"min\": 301.602840423584}}, \"EndTime\": 1567857334.038017, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857333.735989}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=865.081041783 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] #quality_metric: host=algo-1, epoch=8, train loss <loss>=10.2422684564\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] Saved checkpoint to \"/opt/ml/model/state_1e9d13e2-4b95-46b3-9d67-75ec5ac1abb9-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 11.49606704711914, \"sum\": 11.49606704711914, \"min\": 11.49606704711914}}, \"EndTime\": 1567857334.050092, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857334.038085}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] Epoch[9] Batch[0] avg_epoch_loss=10.707192\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=10.707192421\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] Epoch[9] Batch[5] avg_epoch_loss=10.346608\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=10.3466083209\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] Epoch[9] Batch [5]#011Speed: 1923.45 samples/sec#011loss=10.346608\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] processed a total of 280 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 318.4359073638916, \"sum\": 318.4359073638916, \"min\": 318.4359073638916}}, \"EndTime\": 1567857334.36864, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857334.05015}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=879.043774602 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] #quality_metric: host=algo-1, epoch=9, train loss <loss>=10.3431915707\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] Epoch[10] Batch[0] avg_epoch_loss=10.727871\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=10.7278709412\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] Epoch[10] Batch[5] avg_epoch_loss=10.374061\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=10.3740607897\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] Epoch[10] Batch [5]#011Speed: 1911.24 samples/sec#011loss=10.374061\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] processed a total of 251 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 263.81802558898926, \"sum\": 263.81802558898926, \"min\": 263.81802558898926}}, \"EndTime\": 1567857334.633013, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857334.368696}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=951.03091841 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] #quality_metric: host=algo-1, epoch=10, train loss <loss>=10.4456501007\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] Epoch[11] Batch[0] avg_epoch_loss=10.664833\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=10.6648330688\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] Epoch[11] Batch[5] avg_epoch_loss=10.319670\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=10.3196695646\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] Epoch[11] Batch [5]#011Speed: 1733.10 samples/sec#011loss=10.319670\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] processed a total of 230 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 274.2478847503662, \"sum\": 274.2478847503662, \"min\": 274.2478847503662}}, \"EndTime\": 1567857334.907766, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857334.633082}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=838.348314031 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] #quality_metric: host=algo-1, epoch=11, train loss <loss>=10.4983077049\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:34 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] Epoch[12] Batch[0] avg_epoch_loss=10.860762\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=10.8607616425\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] Epoch[12] Batch[5] avg_epoch_loss=10.368974\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=10.368973573\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] Epoch[12] Batch [5]#011Speed: 2019.85 samples/sec#011loss=10.368974\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] processed a total of 274 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 276.839017868042, \"sum\": 276.839017868042, \"min\": 276.839017868042}}, \"EndTime\": 1567857335.185082, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857334.907819}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=989.365711885 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] #quality_metric: host=algo-1, epoch=12, train loss <loss>=10.3478096856\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] Epoch[13] Batch[0] avg_epoch_loss=10.623333\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=10.6233329773\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] Epoch[13] Batch[5] avg_epoch_loss=10.432141\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=10.432141304\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] Epoch[13] Batch [5]#011Speed: 1856.08 samples/sec#011loss=10.432141\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] processed a total of 242 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 258.7242126464844, \"sum\": 258.7242126464844, \"min\": 258.7242126464844}}, \"EndTime\": 1567857335.444372, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857335.185151}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=934.991012302 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] #quality_metric: host=algo-1, epoch=13, train loss <loss>=10.3966211081\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] Epoch[14] Batch[0] avg_epoch_loss=10.521896\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=10.5218963623\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] Epoch[14] Batch[5] avg_epoch_loss=10.334715\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=10.3347150485\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] Epoch[14] Batch [5]#011Speed: 1810.12 samples/sec#011loss=10.334715\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] processed a total of 260 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 304.1870594024658, \"sum\": 304.1870594024658, \"min\": 304.1870594024658}}, \"EndTime\": 1567857335.749192, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857335.444437}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=854.319380608 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] #quality_metric: host=algo-1, epoch=14, train loss <loss>=9.98435688019\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:35 INFO 140078896834368] Saved checkpoint to \"/opt/ml/model/state_90ed5177-1ca4-45fd-8c64-626b37f10412-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 11.972904205322266, \"sum\": 11.972904205322266, \"min\": 11.972904205322266}}, \"EndTime\": 1567857335.761965, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857335.7493}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] Epoch[15] Batch[0] avg_epoch_loss=10.642865\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=10.642865181\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] Epoch[15] Batch[5] avg_epoch_loss=10.341813\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=10.3418129285\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] Epoch[15] Batch [5]#011Speed: 1373.32 samples/sec#011loss=10.341813\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] processed a total of 265 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 428.9720058441162, \"sum\": 428.9720058441162, \"min\": 428.9720058441162}}, \"EndTime\": 1567857336.191116, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857335.762052}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=617.597345337 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] #quality_metric: host=algo-1, epoch=15, train loss <loss>=10.3286321428\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] Epoch[16] Batch[0] avg_epoch_loss=10.323968\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=10.3239679337\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] Epoch[16] Batch[5] avg_epoch_loss=10.431956\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=10.4319556554\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] Epoch[16] Batch [5]#011Speed: 1534.58 samples/sec#011loss=10.431956\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] processed a total of 269 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 397.28498458862305, \"sum\": 397.28498458862305, \"min\": 397.28498458862305}}, \"EndTime\": 1567857336.588928, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857336.191188}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=676.385872885 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] #quality_metric: host=algo-1, epoch=16, train loss <loss>=10.3201358583\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] Epoch[17] Batch[0] avg_epoch_loss=10.018063\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=10.0180625916\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] Epoch[17] Batch[5] avg_epoch_loss=10.238994\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=10.2389941216\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] Epoch[17] Batch [5]#011Speed: 2080.68 samples/sec#011loss=10.238994\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] processed a total of 275 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 360.90707778930664, \"sum\": 360.90707778930664, \"min\": 360.90707778930664}}, \"EndTime\": 1567857336.950884, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857336.589306}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=761.732981206 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] #quality_metric: host=algo-1, epoch=17, train loss <loss>=10.2319369846\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:36 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] Epoch[18] Batch[0] avg_epoch_loss=10.200109\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=10.2001085281\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] Epoch[18] Batch[5] avg_epoch_loss=10.387335\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=10.3873349826\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] Epoch[18] Batch [5]#011Speed: 1992.87 samples/sec#011loss=10.387335\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] processed a total of 272 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 275.3429412841797, \"sum\": 275.3429412841797, \"min\": 275.3429412841797}}, \"EndTime\": 1567857337.226743, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857336.950961}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=987.475072296 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] #quality_metric: host=algo-1, epoch=18, train loss <loss>=10.48203818\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] Epoch[19] Batch[0] avg_epoch_loss=10.392336\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=10.3923358917\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] Epoch[19] Batch[5] avg_epoch_loss=10.285688\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=10.2856880824\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] Epoch[19] Batch [5]#011Speed: 2037.70 samples/sec#011loss=10.285688\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] processed a total of 257 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 277.2221565246582, \"sum\": 277.2221565246582, \"min\": 277.2221565246582}}, \"EndTime\": 1567857337.504465, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857337.226812}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=926.633548873 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] #quality_metric: host=algo-1, epoch=19, train loss <loss>=10.4107659658\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] Epoch[20] Batch[0] avg_epoch_loss=10.849788\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=10.8497877121\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] Epoch[20] Batch[5] avg_epoch_loss=10.428229\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=10.4282290141\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] Epoch[20] Batch [5]#011Speed: 1612.16 samples/sec#011loss=10.428229\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] processed a total of 251 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 293.0271625518799, \"sum\": 293.0271625518799, \"min\": 293.0271625518799}}, \"EndTime\": 1567857337.798217, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857337.504552}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=856.196214998 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] #quality_metric: host=algo-1, epoch=20, train loss <loss>=10.435382247\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] Epoch[21] Batch[0] avg_epoch_loss=10.215693\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:37 INFO 140078896834368] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=10.2156934738\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] Epoch[21] Batch[5] avg_epoch_loss=10.192558\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=10.1925581296\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] Epoch[21] Batch [5]#011Speed: 1802.58 samples/sec#011loss=10.192558\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] processed a total of 270 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 301.98192596435547, \"sum\": 301.98192596435547, \"min\": 301.98192596435547}}, \"EndTime\": 1567857338.100831, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857337.798307}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=893.823672874 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #quality_metric: host=algo-1, epoch=21, train loss <loss>=10.1489196353\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] Epoch[22] Batch[0] avg_epoch_loss=10.854106\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=10.8541059494\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] Epoch[22] Batch[5] avg_epoch_loss=10.498705\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=10.4987053871\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] Epoch[22] Batch [5]#011Speed: 2118.70 samples/sec#011loss=10.498705\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] processed a total of 249 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 253.73506546020508, \"sum\": 253.73506546020508, \"min\": 253.73506546020508}}, \"EndTime\": 1567857338.355084, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857338.100891}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=980.882317417 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #quality_metric: host=algo-1, epoch=22, train loss <loss>=10.3521538973\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] Epoch[23] Batch[0] avg_epoch_loss=10.212411\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=10.2124109268\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] Epoch[23] Batch[5] avg_epoch_loss=10.265206\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=10.2652064959\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] Epoch[23] Batch [5]#011Speed: 1798.44 samples/sec#011loss=10.265206\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] processed a total of 240 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 280.3049087524414, \"sum\": 280.3049087524414, \"min\": 280.3049087524414}}, \"EndTime\": 1567857338.635955, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857338.355163}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=855.831947519 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #quality_metric: host=algo-1, epoch=23, train loss <loss>=10.4507474899\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] Epoch[24] Batch[0] avg_epoch_loss=11.342636\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=11.3426361084\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] Epoch[24] Batch[5] avg_epoch_loss=10.464332\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=10.4643324216\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] Epoch[24] Batch [5]#011Speed: 1377.15 samples/sec#011loss=10.464332\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] processed a total of 267 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 329.47301864624023, \"sum\": 329.47301864624023, \"min\": 329.47301864624023}}, \"EndTime\": 1567857338.966054, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857338.636038}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #throughput_metric: host=algo-1, train throughput=810.040938968 records/second\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #quality_metric: host=algo-1, epoch=24, train loss <loss>=10.366235945\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] loss did not improve\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] Loading parameters from best epoch (14)\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 5.342006683349609, \"sum\": 5.342006683349609, \"min\": 5.342006683349609}}, \"EndTime\": 1567857338.971947, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857338.966126}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] stopping training now\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] Final loss: 9.98435688019 (occurred at epoch 14)\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] #quality_metric: host=algo-1, train final_loss <loss>=9.98435688019\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 WARNING 140078896834368] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:38 INFO 140078896834368] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 58.94207954406738, \"sum\": 58.94207954406738, \"min\": 58.94207954406738}}, \"EndTime\": 1567857339.031596, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857338.972009}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:39 INFO 140078896834368] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 81.15410804748535, \"sum\": 81.15410804748535, \"min\": 81.15410804748535}}, \"EndTime\": 1567857339.053772, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857339.031661}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:39 INFO 140078896834368] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:39 INFO 140078896834368] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 3.9441585540771484, \"sum\": 3.9441585540771484, \"min\": 3.9441585540771484}}, \"EndTime\": 1567857339.057814, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857339.053838}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:39 INFO 140078896834368] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:39 INFO 140078896834368] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 0.03886222839355469, \"sum\": 0.03886222839355469, \"min\": 0.03886222839355469}}, \"EndTime\": 1567857339.058527, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857339.05787}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 1003.3600330352783, \"sum\": 1003.3600330352783, \"min\": 1003.3600330352783}}, \"EndTime\": 1567857340.061851, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857339.058589}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:40 INFO 140078896834368] #test_score (algo-1, RMSE): 8175.81408791\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:40 INFO 140078896834368] #test_score (algo-1, mean_wQuantileLoss): 0.19050473\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:40 INFO 140078896834368] #test_score (algo-1, wQuantileLoss[0.1]): 0.14778939\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:40 INFO 140078896834368] #test_score (algo-1, wQuantileLoss[0.2]): 0.1941401\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:40 INFO 140078896834368] #test_score (algo-1, wQuantileLoss[0.3]): 0.18389034\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:40 INFO 140078896834368] #test_score (algo-1, wQuantileLoss[0.4]): 0.14758423\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:40 INFO 140078896834368] #test_score (algo-1, wQuantileLoss[0.5]): 0.15476686\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:40 INFO 140078896834368] #test_score (algo-1, wQuantileLoss[0.6]): 0.21544625\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:40 INFO 140078896834368] #test_score (algo-1, wQuantileLoss[0.7]): 0.2525445\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:40 INFO 140078896834368] #test_score (algo-1, wQuantileLoss[0.8]): 0.24209614\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:40 INFO 140078896834368] #test_score (algo-1, wQuantileLoss[0.9]): 0.17628482\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:40 INFO 140078896834368] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.190504729748\u001b[0m\n",
      "\u001b[31m[09/07/2019 11:55:40 INFO 140078896834368] #quality_metric: host=algo-1, test RMSE <loss>=8175.81408791\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 9169.297933578491, \"sum\": 9169.297933578491, \"min\": 9169.297933578491}, \"setuptime\": {\"count\": 1, \"max\": 8.819103240966797, \"sum\": 8.819103240966797, \"min\": 8.819103240966797}}, \"EndTime\": 1567857340.070688, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1567857340.061941}\n",
      "\u001b[0m\n",
      "\n",
      "2019-09-07 11:55:50 Completed - Training job completed\n",
      "Training seconds: 64\n",
      "Billable seconds: 64\n"
     ]
    }
   ],
   "source": [
    "data_channels = {\"train\": train_path, \"test\": test_path}\n",
    "deepAR.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "deepAR_predictor = deepAR.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sales:  [103340.4375, 100201.9296875, 104847.8828125, 101342.5625, 120300.0234375, 98441.6484375, 103531.828125, 99472.0078125, 107157.6875]\n",
      "Actual Sales:  [100422.86, 94987.08, 90889.75, 115695.71, 100372.02, 96616.19, 93460.57, 99398.64, 105059.88]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Predict last 9 weeks of a department and compare to ground truth\n",
    "\n",
    "deepAR_predictor.content_type = 'application/json'\n",
    "dept = 90 \n",
    "\n",
    "prediction_data = da.salesinference.buildInferenceData(dept, trainingSet, testSet)\n",
    "#print(prediction_data)\n",
    "\n",
    "result = deepAR_predictor.predict(prediction_data)\n",
    "\n",
    "y_mean, y_q1, y_q2, y_sample = da.salesinference.getInferenceSeries(result)\n",
    "print(\"Predicted Sales: \", y_mean)\n",
    "print(\"Actual Sales: \", list(testSet[dept]['Weekly_Sales'][134:]))\n",
    "\n",
    "da.salesinference.plotResults(prediction_length, result, truth=True, truth_data=testSet[dept]['Weekly_Sales'][134:], truth_label='truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
